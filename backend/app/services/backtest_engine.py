"""
Backtest Engine - Walk-Forward Backtesting with VectorBT

This module provides institutional-grade backtesting capabilities using VectorBT (FREE).
It validates ML-detected patterns against historical data to prevent overfitting.

Key Features:
- Walk-forward testing (Train 60% â†’ Test 40% â†’ Repeat)
- Pattern-specific backtesting
- Performance metrics (Sharpe, Sortino, Max DD, etc.)
- Prevents overfitting - the biggest backtest mistake

100% FREE - Uses VectorBT + yfinance only.
"""

import json
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum

# Try to import vectorbt - it's optional but recommended
try:
    import vectorbt as vbt
    VECTORBT_AVAILABLE = True
except ImportError:
    VECTORBT_AVAILABLE = False
    print("VectorBT not installed. Install with: pip install vectorbt")

# yfinance for free historical data
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False


class BacktestMode(Enum):
    """Backtesting modes"""
    SIMPLE = "simple"              # Basic backtest (prone to overfitting)
    WALK_FORWARD = "walk_forward"  # Walk-forward (institutional standard)
    MONTE_CARLO = "monte_carlo"    # Randomized simulation


@dataclass
class BacktestResult:
    """Results from a backtest run"""
    # Identification
    pattern_type: str
    symbol: str
    timeframe: str
    start_date: str
    end_date: str
    mode: str

    # Core Metrics
    total_trades: int
    winning_trades: int
    losing_trades: int
    win_rate: float

    # Returns
    total_return: float
    annualized_return: float

    # Risk Metrics
    sharpe_ratio: float
    sortino_ratio: float
    calmar_ratio: float
    max_drawdown: float
    max_drawdown_duration_days: int

    # Trade Metrics
    avg_trade_return: float
    avg_winning_trade: float
    avg_losing_trade: float
    profit_factor: float
    expectancy: float

    # Walk-Forward Specific
    in_sample_sharpe: Optional[float] = None
    out_of_sample_sharpe: Optional[float] = None
    robustness_ratio: Optional[float] = None  # OOS/IS ratio (>0.5 is good)

    # Timestamp
    backtest_timestamp: str = ""

    def __post_init__(self):
        if not self.backtest_timestamp:
            self.backtest_timestamp = datetime.now().isoformat()

    def to_dict(self) -> Dict:
        return asdict(self)

    def is_profitable(self) -> bool:
        """Check if strategy is profitable"""
        return self.total_return > 0 and self.expectancy > 0

    def is_robust(self) -> bool:
        """Check if strategy is robust (not overfit)"""
        if self.robustness_ratio is not None:
            return self.robustness_ratio > 0.5
        return self.sharpe_ratio > 0.5


class PatternBacktester:
    """
    Backtests ICT patterns using historical data.

    This is what separates retail from institutional:
    - Retail: "I think this pattern works"
    - Institutional: "This pattern has 67% win rate with 1.8 Sharpe over 500 trades"
    """

    def __init__(self, data_dir: str = None):
        self.data_dir = Path(data_dir) if data_dir else Path(__file__).parent.parent.parent.parent / "data"
        self.results_dir = self.data_dir / "backtest_results"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # Cache for historical data
        self._data_cache: Dict[str, pd.DataFrame] = {}

    def fetch_historical_data(
        self,
        symbol: str,
        start_date: str,
        end_date: str,
        interval: str = "1h"
    ) -> Optional[pd.DataFrame]:
        """
        Fetch historical OHLCV data using yfinance (FREE).

        Args:
            symbol: Trading symbol (e.g., "EURUSD=X", "BTC-USD", "SPY")
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
            interval: Candle interval (1m, 5m, 15m, 1h, 1d)

        Returns:
            DataFrame with OHLCV data
        """
        if not YFINANCE_AVAILABLE:
            print("yfinance not available")
            return None

        cache_key = f"{symbol}_{start_date}_{end_date}_{interval}"
        if cache_key in self._data_cache:
            return self._data_cache[cache_key]

        try:
            # Convert forex pairs for yfinance
            yf_symbol = symbol
            if "/" in symbol:
                yf_symbol = symbol.replace("/", "") + "=X"

            ticker = yf.Ticker(yf_symbol)
            df = ticker.history(start=start_date, end=end_date, interval=interval)

            if df.empty:
                print(f"No data found for {symbol}")
                return None

            # Standardize column names
            df.columns = [c.lower() for c in df.columns]

            self._data_cache[cache_key] = df
            return df

        except Exception as e:
            print(f"Error fetching data for {symbol}: {e}")
            return None

    def generate_pattern_signals(
        self,
        df: pd.DataFrame,
        pattern_type: str,
        pattern_params: Dict = None
    ) -> pd.Series:
        """
        Generate entry signals based on pattern detection.

        This simulates what our ML would detect on historical data.
        Returns a Series of 1 (long), -1 (short), or 0 (no signal).
        """
        signals = pd.Series(0, index=df.index)
        params = pattern_params or {}

        if pattern_type == "fvg":
            # Fair Value Gap detection
            signals = self._detect_fvg_signals(df, params)

        elif pattern_type == "order_block":
            # Order Block detection
            signals = self._detect_ob_signals(df, params)

        elif pattern_type == "liquidity_sweep":
            # Liquidity sweep detection
            signals = self._detect_liquidity_signals(df, params)

        elif pattern_type == "market_structure":
            # BOS/CHoCH detection
            signals = self._detect_structure_signals(df, params)

        return signals

    def _detect_fvg_signals(self, df: pd.DataFrame, params: Dict) -> pd.Series:
        """Detect Fair Value Gap signals"""
        signals = pd.Series(0, index=df.index)
        min_gap_pct = params.get('min_gap_pct', 0.001)  # 0.1% minimum gap

        for i in range(2, len(df)):
            # Bullish FVG: candle[i-2].high < candle[i].low
            if df['high'].iloc[i-2] < df['low'].iloc[i]:
                gap_size = (df['low'].iloc[i] - df['high'].iloc[i-2]) / df['close'].iloc[i-1]
                if gap_size >= min_gap_pct:
                    signals.iloc[i] = 1  # Long signal

            # Bearish FVG: candle[i-2].low > candle[i].high
            elif df['low'].iloc[i-2] > df['high'].iloc[i]:
                gap_size = (df['low'].iloc[i-2] - df['high'].iloc[i]) / df['close'].iloc[i-1]
                if gap_size >= min_gap_pct:
                    signals.iloc[i] = -1  # Short signal

        return signals

    def _detect_ob_signals(self, df: pd.DataFrame, params: Dict) -> pd.Series:
        """Detect Order Block signals"""
        signals = pd.Series(0, index=df.index)
        lookback = params.get('lookback', 5)
        impulse_multiplier = params.get('impulse_multiplier', 1.5)

        # Calculate average candle size
        avg_size = (df['high'] - df['low']).rolling(20).mean()

        for i in range(lookback + 1, len(df)):
            # Check for impulse move (larger than average)
            current_size = df['high'].iloc[i] - df['low'].iloc[i]

            if current_size > avg_size.iloc[i] * impulse_multiplier:
                # Bullish impulse - look for bearish candle before
                if df['close'].iloc[i] > df['open'].iloc[i]:  # Bullish candle
                    # Find last bearish candle
                    for j in range(i-1, max(i-lookback, 0), -1):
                        if df['close'].iloc[j] < df['open'].iloc[j]:  # Bearish
                            signals.iloc[i] = 1
                            break

                # Bearish impulse
                elif df['close'].iloc[i] < df['open'].iloc[i]:  # Bearish candle
                    for j in range(i-1, max(i-lookback, 0), -1):
                        if df['close'].iloc[j] > df['open'].iloc[j]:  # Bullish
                            signals.iloc[i] = -1
                            break

        return signals

    def _detect_liquidity_signals(self, df: pd.DataFrame, params: Dict) -> pd.Series:
        """Detect liquidity sweep signals"""
        signals = pd.Series(0, index=df.index)
        lookback = params.get('lookback', 20)

        for i in range(lookback, len(df)):
            window = df.iloc[i-lookback:i]

            # Sweep of highs (bearish)
            if df['high'].iloc[i] > window['high'].max():
                if df['close'].iloc[i] < df['open'].iloc[i]:  # Bearish close
                    signals.iloc[i] = -1

            # Sweep of lows (bullish)
            if df['low'].iloc[i] < window['low'].min():
                if df['close'].iloc[i] > df['open'].iloc[i]:  # Bullish close
                    signals.iloc[i] = 1

        return signals

    def _detect_structure_signals(self, df: pd.DataFrame, params: Dict) -> pd.Series:
        """Detect market structure break signals"""
        signals = pd.Series(0, index=df.index)
        lookback = params.get('lookback', 10)

        # Find swing highs and lows
        swing_highs = df['high'].rolling(lookback, center=True).max() == df['high']
        swing_lows = df['low'].rolling(lookback, center=True).min() == df['low']

        last_swing_high = None
        last_swing_low = None

        for i in range(lookback, len(df) - lookback):
            if swing_highs.iloc[i]:
                last_swing_high = df['high'].iloc[i]
            if swing_lows.iloc[i]:
                last_swing_low = df['low'].iloc[i]

            # Break of structure
            if last_swing_high and df['close'].iloc[i] > last_swing_high:
                signals.iloc[i] = 1  # Bullish BOS
                last_swing_high = df['high'].iloc[i]

            if last_swing_low and df['close'].iloc[i] < last_swing_low:
                signals.iloc[i] = -1  # Bearish BOS
                last_swing_low = df['low'].iloc[i]

        return signals

    def run_simple_backtest(
        self,
        symbol: str,
        pattern_type: str,
        start_date: str,
        end_date: str,
        interval: str = "1h",
        stop_loss_pct: float = 0.01,
        take_profit_pct: float = 0.02,
        pattern_params: Dict = None
    ) -> Optional[BacktestResult]:
        """
        Run a simple backtest (WARNING: prone to overfitting).

        Use walk_forward_backtest() for more reliable results.
        """
        df = self.fetch_historical_data(symbol, start_date, end_date, interval)
        if df is None or len(df) < 100:
            return None

        signals = self.generate_pattern_signals(df, pattern_type, pattern_params)

        # Simulate trades
        trades = self._simulate_trades(df, signals, stop_loss_pct, take_profit_pct)

        if not trades:
            return None

        # Calculate metrics
        return self._calculate_metrics(
            trades=trades,
            df=df,
            pattern_type=pattern_type,
            symbol=symbol,
            timeframe=interval,
            start_date=start_date,
            end_date=end_date,
            mode=BacktestMode.SIMPLE.value
        )

    def walk_forward_backtest(
        self,
        symbol: str,
        pattern_type: str,
        start_date: str,
        end_date: str,
        interval: str = "1h",
        train_pct: float = 0.6,
        num_folds: int = 5,
        stop_loss_pct: float = 0.01,
        take_profit_pct: float = 0.02,
        pattern_params: Dict = None
    ) -> Optional[BacktestResult]:
        """
        Walk-forward backtest - THE INSTITUTIONAL STANDARD.

        This prevents overfitting by:
        1. Splitting data into train/test periods
        2. Optimizing on train, validating on test
        3. Repeating across multiple periods
        4. Measuring robustness (OOS vs IS performance)

        Args:
            train_pct: Percentage of each fold for training (0.6 = 60%)
            num_folds: Number of walk-forward periods
        """
        df = self.fetch_historical_data(symbol, start_date, end_date, interval)
        if df is None or len(df) < 200:
            return None

        fold_size = len(df) // num_folds
        all_trades = []
        in_sample_returns = []
        out_sample_returns = []

        for fold in range(num_folds):
            fold_start = fold * fold_size
            fold_end = fold_start + fold_size

            if fold_end > len(df):
                break

            fold_data = df.iloc[fold_start:fold_end]
            train_size = int(len(fold_data) * train_pct)

            train_data = fold_data.iloc[:train_size]
            test_data = fold_data.iloc[train_size:]

            # Generate signals on both
            train_signals = self.generate_pattern_signals(train_data, pattern_type, pattern_params)
            test_signals = self.generate_pattern_signals(test_data, pattern_type, pattern_params)

            # Simulate trades
            train_trades = self._simulate_trades(train_data, train_signals, stop_loss_pct, take_profit_pct)
            test_trades = self._simulate_trades(test_data, test_signals, stop_loss_pct, take_profit_pct)

            if train_trades:
                in_sample_returns.extend([t['return'] for t in train_trades])
            if test_trades:
                out_sample_returns.extend([t['return'] for t in test_trades])
                all_trades.extend(test_trades)  # Only count OOS trades

        if not all_trades:
            return None

        # Calculate metrics from OOS trades only
        result = self._calculate_metrics(
            trades=all_trades,
            df=df,
            pattern_type=pattern_type,
            symbol=symbol,
            timeframe=interval,
            start_date=start_date,
            end_date=end_date,
            mode=BacktestMode.WALK_FORWARD.value
        )

        # Calculate robustness metrics
        if in_sample_returns and out_sample_returns:
            is_sharpe = self._calculate_sharpe(in_sample_returns)
            oos_sharpe = self._calculate_sharpe(out_sample_returns)

            result.in_sample_sharpe = is_sharpe
            result.out_of_sample_sharpe = oos_sharpe
            result.robustness_ratio = oos_sharpe / is_sharpe if is_sharpe > 0 else 0

        return result

    def _simulate_trades(
        self,
        df: pd.DataFrame,
        signals: pd.Series,
        stop_loss_pct: float,
        take_profit_pct: float
    ) -> List[Dict]:
        """Simulate trades based on signals"""
        trades = []
        position = None

        for i in range(len(df)):
            if signals.iloc[i] != 0 and position is None:
                # Open position
                entry_price = df['close'].iloc[i]
                direction = signals.iloc[i]

                if direction == 1:  # Long
                    stop_loss = entry_price * (1 - stop_loss_pct)
                    take_profit = entry_price * (1 + take_profit_pct)
                else:  # Short
                    stop_loss = entry_price * (1 + stop_loss_pct)
                    take_profit = entry_price * (1 - take_profit_pct)

                position = {
                    'entry_idx': i,
                    'entry_price': entry_price,
                    'direction': direction,
                    'stop_loss': stop_loss,
                    'take_profit': take_profit
                }

            elif position is not None:
                # Check exit conditions
                high = df['high'].iloc[i]
                low = df['low'].iloc[i]

                exit_price = None
                exit_reason = None

                if position['direction'] == 1:  # Long position
                    if low <= position['stop_loss']:
                        exit_price = position['stop_loss']
                        exit_reason = 'stop_loss'
                    elif high >= position['take_profit']:
                        exit_price = position['take_profit']
                        exit_reason = 'take_profit'
                else:  # Short position
                    if high >= position['stop_loss']:
                        exit_price = position['stop_loss']
                        exit_reason = 'stop_loss'
                    elif low <= position['take_profit']:
                        exit_price = position['take_profit']
                        exit_reason = 'take_profit'

                if exit_price:
                    # Calculate return
                    if position['direction'] == 1:
                        trade_return = (exit_price - position['entry_price']) / position['entry_price']
                    else:
                        trade_return = (position['entry_price'] - exit_price) / position['entry_price']

                    trades.append({
                        'entry_idx': position['entry_idx'],
                        'exit_idx': i,
                        'entry_price': position['entry_price'],
                        'exit_price': exit_price,
                        'direction': position['direction'],
                        'return': trade_return,
                        'exit_reason': exit_reason,
                        'win': trade_return > 0
                    })

                    position = None

        return trades

    def _calculate_metrics(
        self,
        trades: List[Dict],
        df: pd.DataFrame,
        pattern_type: str,
        symbol: str,
        timeframe: str,
        start_date: str,
        end_date: str,
        mode: str
    ) -> BacktestResult:
        """Calculate comprehensive backtest metrics"""
        returns = [t['return'] for t in trades]
        wins = [t for t in trades if t['win']]
        losses = [t for t in trades if not t['win']]

        total_trades = len(trades)
        winning_trades = len(wins)
        losing_trades = len(losses)
        win_rate = winning_trades / total_trades if total_trades > 0 else 0

        # Returns
        total_return = sum(returns)
        days = (df.index[-1] - df.index[0]).days if hasattr(df.index, '__getitem__') else 365
        annualized_return = total_return * (365 / max(days, 1))

        # Trade metrics
        avg_trade_return = np.mean(returns) if returns else 0
        avg_winning_trade = np.mean([t['return'] for t in wins]) if wins else 0
        avg_losing_trade = np.mean([t['return'] for t in losses]) if losses else 0

        # Profit factor
        gross_profit = sum([t['return'] for t in wins]) if wins else 0
        gross_loss = abs(sum([t['return'] for t in losses])) if losses else 1
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else gross_profit

        # Expectancy
        expectancy = (win_rate * avg_winning_trade) - ((1 - win_rate) * abs(avg_losing_trade))

        # Risk metrics
        sharpe_ratio = self._calculate_sharpe(returns)
        sortino_ratio = self._calculate_sortino(returns)
        max_dd, max_dd_duration = self._calculate_max_drawdown(returns)
        calmar_ratio = annualized_return / abs(max_dd) if max_dd != 0 else 0

        return BacktestResult(
            pattern_type=pattern_type,
            symbol=symbol,
            timeframe=timeframe,
            start_date=start_date,
            end_date=end_date,
            mode=mode,
            total_trades=total_trades,
            winning_trades=winning_trades,
            losing_trades=losing_trades,
            win_rate=win_rate,
            total_return=total_return,
            annualized_return=annualized_return,
            sharpe_ratio=sharpe_ratio,
            sortino_ratio=sortino_ratio,
            calmar_ratio=calmar_ratio,
            max_drawdown=max_dd,
            max_drawdown_duration_days=max_dd_duration,
            avg_trade_return=avg_trade_return,
            avg_winning_trade=avg_winning_trade,
            avg_losing_trade=avg_losing_trade,
            profit_factor=profit_factor,
            expectancy=expectancy
        )

    def _calculate_sharpe(self, returns: List[float], risk_free_rate: float = 0.02) -> float:
        """Calculate Sharpe Ratio"""
        if not returns or len(returns) < 2:
            return 0

        returns_arr = np.array(returns)
        excess_returns = returns_arr - (risk_free_rate / 252)  # Daily risk-free rate

        if np.std(excess_returns) == 0:
            return 0

        return np.sqrt(252) * np.mean(excess_returns) / np.std(excess_returns)

    def _calculate_sortino(self, returns: List[float], risk_free_rate: float = 0.02) -> float:
        """Calculate Sortino Ratio (only penalizes downside volatility)"""
        if not returns or len(returns) < 2:
            return 0

        returns_arr = np.array(returns)
        excess_returns = returns_arr - (risk_free_rate / 252)

        downside_returns = returns_arr[returns_arr < 0]
        if len(downside_returns) == 0:
            return float('inf') if np.mean(excess_returns) > 0 else 0

        downside_std = np.std(downside_returns)
        if downside_std == 0:
            return 0

        return np.sqrt(252) * np.mean(excess_returns) / downside_std

    def _calculate_max_drawdown(self, returns: List[float]) -> Tuple[float, int]:
        """Calculate maximum drawdown and duration"""
        if not returns:
            return 0, 0

        cumulative = np.cumprod(1 + np.array(returns))
        running_max = np.maximum.accumulate(cumulative)
        drawdowns = (cumulative - running_max) / running_max

        max_dd = np.min(drawdowns)

        # Calculate duration
        in_drawdown = drawdowns < 0
        max_duration = 0
        current_duration = 0

        for is_dd in in_drawdown:
            if is_dd:
                current_duration += 1
                max_duration = max(max_duration, current_duration)
            else:
                current_duration = 0

        return max_dd, max_duration

    def save_result(self, result: BacktestResult) -> str:
        """Save backtest result to file"""
        filename = f"{result.pattern_type}_{result.symbol}_{result.backtest_timestamp[:10]}.json"
        filepath = self.results_dir / filename

        with open(filepath, 'w') as f:
            json.dump(result.to_dict(), f, indent=2)

        return str(filepath)

    def load_results(self, pattern_type: str = None) -> List[BacktestResult]:
        """Load saved backtest results"""
        results = []

        for filepath in self.results_dir.glob("*.json"):
            if pattern_type and pattern_type not in filepath.name:
                continue

            with open(filepath, 'r') as f:
                data = json.load(f)
                results.append(BacktestResult(**data))

        return results


# Singleton instance
_backtester: Optional[PatternBacktester] = None


def get_backtester() -> PatternBacktester:
    """Get or create the singleton backtester instance"""
    global _backtester
    if _backtester is None:
        _backtester = PatternBacktester()
    return _backtester


def backtest_pattern(
    symbol: str,
    pattern_type: str,
    start_date: str = None,
    end_date: str = None,
    walk_forward: bool = True
) -> Optional[BacktestResult]:
    """
    Convenience function to backtest a pattern.

    Args:
        symbol: Trading symbol
        pattern_type: Pattern type (fvg, order_block, liquidity_sweep, market_structure)
        start_date: Start date (default: 1 year ago)
        end_date: End date (default: today)
        walk_forward: Use walk-forward testing (recommended)

    Returns:
        BacktestResult or None if failed
    """
    backtester = get_backtester()

    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if not start_date:
        start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")

    if walk_forward:
        return backtester.walk_forward_backtest(
            symbol=symbol,
            pattern_type=pattern_type,
            start_date=start_date,
            end_date=end_date
        )
    else:
        return backtester.run_simple_backtest(
            symbol=symbol,
            pattern_type=pattern_type,
            start_date=start_date,
            end_date=end_date
        )


# Test function
def test_backtest_engine():
    """Test the backtest engine"""
    print("=" * 60)
    print("BACKTEST ENGINE TEST")
    print("=" * 60)

    backtester = get_backtester()

    # Test with SPY (most liquid, best data)
    print("\nRunning walk-forward backtest on SPY (FVG pattern)...")

    result = backtester.walk_forward_backtest(
        symbol="SPY",
        pattern_type="fvg",
        start_date="2023-01-01",
        end_date="2024-01-01",
        interval="1h"
    )

    if result:
        print(f"\nðŸ“Š BACKTEST RESULTS")
        print(f"{'='*40}")
        print(f"Pattern: {result.pattern_type}")
        print(f"Symbol: {result.symbol}")
        print(f"Mode: {result.mode}")
        print(f"\nðŸ“ˆ PERFORMANCE:")
        print(f"  Total Trades: {result.total_trades}")
        print(f"  Win Rate: {result.win_rate:.1%}")
        print(f"  Total Return: {result.total_return:.2%}")
        print(f"  Profit Factor: {result.profit_factor:.2f}")
        print(f"  Expectancy: {result.expectancy:.4f}")
        print(f"\nðŸ“‰ RISK METRICS:")
        print(f"  Sharpe Ratio: {result.sharpe_ratio:.2f}")
        print(f"  Sortino Ratio: {result.sortino_ratio:.2f}")
        print(f"  Max Drawdown: {result.max_drawdown:.2%}")
        print(f"\nðŸŽ¯ ROBUSTNESS:")
        print(f"  In-Sample Sharpe: {result.in_sample_sharpe:.2f}" if result.in_sample_sharpe else "  N/A")
        print(f"  Out-of-Sample Sharpe: {result.out_of_sample_sharpe:.2f}" if result.out_of_sample_sharpe else "  N/A")
        print(f"  Robustness Ratio: {result.robustness_ratio:.2f}" if result.robustness_ratio else "  N/A")
        print(f"\nâœ… Is Profitable: {result.is_profitable()}")
        print(f"âœ… Is Robust: {result.is_robust()}")

        # Save result
        filepath = backtester.save_result(result)
        print(f"\nResult saved to: {filepath}")
    else:
        print("Backtest failed - no trades generated")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    test_backtest_engine()
